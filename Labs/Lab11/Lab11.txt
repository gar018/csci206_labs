Question 5: (See Lab11logdata)
1.
When the block size increases from 8 to 64, our miss rate decreases.
This is since larger block sizes equate to larger size of data being stored within the cache.

2.
When cache size was doubled, our miss rate saw a drop from 7% to 5%. While this was better performance, the cache size was signifcantly increased only for a small bump in hits.
This is why large cache size is not necessarily better, since it gives diminishing returns.

3.
For 32k, 64k, 128k, and 256k cache sizes, our miss rates were 1.8%, 1.5%, 1.3%, and 1.2% respectively.
These were not significant reductions in miss rate, and further reinforce that cache size has a point at which its significance becomes reduced.

4.
Increasing the way of our cache reduces our miss rate heavily for our 2 and 4 way caches. This is expected, as a larger way cache can store data based around a similar memory address easier, which is common in instruction sets.

5.
Creating a larger 128k sized 2 and 4 way cache showed only small drops in miss rate for both ways compared to our 8k cache sizes.

Question 6: (See Lab11logdata)

For this question my blocked log used 32 bytes for the block size.

The results of my cache analysis has shown that a 8192 byte cache with a 32 byte block size and 256 ways was best fit to reduce the number of misses in the instruction set.
Additionally, I found that using the formula 'block_size*associativty=cache_size' was the best way to look for optimized hit counts. My data shows different variations of block size and associativity that fit my cache size formula in attempt to find the lowest miss rate.
Associativity was the most important factor from my trials. Increasing the way decreased miss rate significantly. There were too bottlenecks to this, however. Increasing the way increased the time complexity of my cache. At 512 way it took much longer to process than 256. 512 produced the same results as 256 as well.
Block size had a curve to effectiveness. 32 bytes was better than 16 in most cases, but 64 was not better than 32. Thus I kept 32 as a happy medium.
Finally, changing cache size from 8192 to 16384 did nothing to reduce miss rate, and actually happened to share the same results as my 256 way vs 512 way test.

In conclusion, a low cache size can be used in conjunction with a 32 byte block size and an n-way associativity (such that our formula holds true) to create a heavily optimized cache without spending spatial complexity on byte size.

